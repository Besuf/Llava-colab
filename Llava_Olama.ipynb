{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd34a00",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Besuf/Llava-colab/blob/main/Llava_Olama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f28865",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install -y pciutils\n",
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start/restart Ollama and wait for port 11434 to be ready\n",
    "!pkill -f \"ollama serve\" || true\n",
    "%env OLLAMA_NUM_GPU=1\n",
    "%env OLLAMA_KEEP_ALIVE=30m\n",
    "!nohup ollama serve > /content/ollama.log 2>&1 &\n",
    "\n",
    "import time, requests, os\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"\n",
    "\n",
    "def wait_for_ollama(timeout=120):\n",
    "    t0 = time.time()\n",
    "    while time.time() - t0 < timeout:\n",
    "        try:\n",
    "            r = requests.get(f\"{BASE}/api/version\", timeout=2)\n",
    "            if r.ok:\n",
    "                print(\"Ollama up:\", r.json())\n",
    "                return True\n",
    "        except Exception:\n",
    "            pass\n",
    "        time.sleep(1)\n",
    "    print(\"Timeout waiting for Ollama. Last logs:\")\n",
    "    os.system(\"tail -n 80 /content/ollama.log\")\n",
    "    return False\n",
    "\n",
    "assert wait_for_ollama(), \"Ollama server did not start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4107812",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llava:7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"\n",
    "\n",
    "# 1) Confirm server responding\n",
    "ver = requests.get(f\"{BASE}/api/version\", timeout=5)\n",
    "ver.raise_for_status()\n",
    "\n",
    "# 2) Confirm model tag present\n",
    "tags = requests.get(f\"{BASE}/api/tags\", timeout=10).json()\n",
    "assert any(m.get(\"name\",\"\").startswith(\"llava:7b\") for m in tags.get(\"models\", [])), \"llava:7b not found in tags\"\n",
    "\n",
    "# 3) Simple chat test (text only)\n",
    "payload = {\n",
    "    \"model\": \"llava:7b\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Say: ready.\"}],\n",
    "    \"stream\": False\n",
    "}\n",
    "resp = requests.post(f\"{BASE}/api/chat\", json=payload, timeout=180)\n",
    "resp.raise_for_status()\n",
    "\n",
    "# Handle single JSON or accidental NDJSON\n",
    "try:\n",
    "    data = resp.json()\n",
    "except Exception:\n",
    "    lines = [l for l in resp.text.splitlines() if l.strip()]\n",
    "    objs = []\n",
    "    for l in lines:\n",
    "        try:\n",
    "            objs.append(json.loads(l))\n",
    "        except:\n",
    "            pass\n",
    "    assert objs, \"No parseable JSON in response\"\n",
    "    data = objs[-1]\n",
    "\n",
    "text = data.get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "assert text, \"Empty content from llava:7b\"\n",
    "\n",
    "print(f\"llava:7b chat OK on 11434 -> {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b801689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import base64, requests, os\n",
    "from IPython.display import Markdown, display, Image as IPyImage\n",
    "\n",
    "BASE = \"http://127.0.0.1:11434\"\n",
    "\n",
    "def b64_image(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def caption_and_tags(image_path, temperature=0.1):\n",
    "    # Ask for plain text with two lines\n",
    "    system = (\n",
    "        \"You are an assistant for image captioning and tag generation.\\n\"\n",
    "        \"Respond as plain text in exactly two lines:\\n\"\n",
    "        \"Caption: <one sentence>\\n\"\n",
    "        \"Tags: <8-12 comma-separated tags>\"\n",
    "    )\n",
    "    user = \"Describe the image and generate tags.\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"llava:7b\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": user, \"images\": [b64_image(image_path)]},\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": temperature},\n",
    "    }\n",
    "    r = requests.post(f\"{BASE}/api/chat\", json=payload, timeout=600)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"message\", {}).get(\"content\", \"\").strip()\n",
    "\n",
    "# Set the image path in Colab (adjust if you cloned the repo)\n",
    "img = \"image1.png\"  # or \"/content/Llava-colab/image1.png\"\n",
    "if not os.path.exists(img):\n",
    "    raise FileNotFoundError(f\"Image not found: {img}. CWD: {os.getcwd()}\")\n",
    "\n",
    "# 1) Show the image\n",
    "display(IPyImage(filename=img))\n",
    "\n",
    "# 2) Show raw plain-text response\n",
    "out = caption_and_tags(img)\n",
    "print(out)                 # plain text\n",
    "# or nice rendering:\n",
    "display(Markdown(out.replace(\"\\n\", \"  \\n\")))\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
